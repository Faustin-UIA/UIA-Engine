name: UIA Bench (Claude Main)

on:
  workflow_dispatch:

permissions:
  contents: write

concurrency:
  group: uia-bench-claude-${{ github.ref }}
  cancel-in-progress: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 360 prompts × 2 phases

    env:
      PROVIDER: anthropic
      MODEL: claude-sonnet-4-20250514
      CONCURRENCY: '4'
      T: '0.2'
      MAXTOK: '120'
      ERROR_THRESHOLD: '10'   # percent

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Install dependencies
        run: |
          set -e
          npm ci || npm i
          # Anthropic SDK avec support messages.stream (aligne avec ton local)
          npm i -E @anthropic-ai/sdk@^0.68.0

      - name: Preflight Anthropic key/model
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          set -euo pipefail
          node --input-type=module -e '
            try {
              const { default: Anthropic } = await import("@anthropic-ai/sdk");
              const c = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
              const model = process.env.MODEL || "claude-sonnet-4-20250514";
              const r = await c.messages.create({
                model, max_tokens: 5,
                messages: [{ role: "user", content: "hi" }]
              });
              console.log("✅ Preflight OK:", model, "-", (r?.content?.[0]?.type || "text"));
            } catch (e) {
              console.error("❌ Anthropic error detail:", e?.message || e);
              process.exit(1);
            }
          '

      - name: Run UIA Bench (Claude)
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          PROVIDER: ${{ env.PROVIDER }}
          MODEL: ${{ env.MODEL }}
        run: |
          set -euo pipefail
          mkdir -p results
          TS=$(date -u +"%Y-%m-%dT%H%M%SZ")
          LOG="results/uia_claude_${TS}.jsonl"

          echo "::notice title=UIA Bench::Running with model ${MODEL}"
          echo "LOG_PATH=${LOG}" >> "$GITHUB_ENV"
          echo "MODEL=${MODEL}"   >> "$GITHUB_ENV"

          node index.js \
            --A=all \
            --prompts=all \
            --concurrency="${CONCURRENCY}" \
            --model="${MODEL}" \
            --t="${T}" \
            --max_tokens="${MAXTOK}" \
            --metrics=true \
            --diag=true \
            --phase_basis=entropy \
            --log="${LOG}"

      - name: Verify results (events + STREAM_SUMMARY)
        run: |
          set -euo pipefail
          LOG="${{ env.LOG_PATH }}"
          THRESH="${ERROR_THRESHOLD:-10}"

          echo "=== Vérification des résultats ==="
          echo "  Log: ${LOG}"
          echo "  Seuil d'échec: ${THRESH}%"

          if [ ! -f "$LOG" ]; then
            echo "::error::Aucun fichier de résultats trouvé (${LOG})"
            exit 1
          fi

          # Compteurs robustes (toujours initialisés)
          RES=0; ERRORS=0; SUM=0
          RES=$(grep -c '"event":"PROMPT_RESULT"'  "$LOG" || true)
          ERRORS=$(grep -c '"event":"PROMPT_ERROR"' "$LOG" || true)
          SUM=$(grep -c '"event":"STREAM_SUMMARY"'  "$LOG" || true)

          # Normaliser en entiers (évite arithmétique sur vide)
          RES=$(( RES + 0 ))
          ERRORS=$(( ERRORS + 0 ))
          SUM=$(( SUM + 0 ))

          echo "  PROMPT_RESULT : ${RES}"
          echo "  PROMPT_ERROR  : ${ERRORS}"
          echo "  STREAM_SUMMARY: ${SUM}"

          TOTAL=$(( RES + ERRORS ))
          if [ "$TOTAL" -eq 0 ]; then
            echo "::error::Aucun événement PROMPT_RESULT/PROMPT_ERROR dans le log."
            exit 1
          fi

          # Taux d'erreur
          ERROR_RATE=$(( ERRORS * 100 / TOTAL ))
          echo "  Taux d'erreur : ${ERROR_RATE}%"
          if [ "$ERROR_RATE" -gt "$THRESH" ]; then
            echo "::error title=High Error Rate::Taux d'erreur trop élevé: ${ERROR_RATE}%"
            exit 1
          fi

          # STREAM_SUMMARY attendu au moins égal au nombre de PROMPT_RESULT
          if [ "$SUM" -lt "$RES" ]; then
            echo "::error title=Missing STREAM_SUMMARY::STREAM_SUMMARY manquants (SUM=${SUM} < RES=${RES})."
            echo "Conseil: vérifier le streaming Anthropic dans index.js (messages.stream) et --diag=true."
            exit 1
          fi

          echo "=== Aperçu STREAM_SUMMARY (5 lignes) ==="
          grep '"event":"STREAM_SUMMARY"' "$LOG" | head -5 || true

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: uia-claude-results-${{ github.run_id }}
          path: ${{ env.LOG_PATH }}
          if-no-files-found: error
          retention-days: 30

      - name: Summarize
        run: |
          set -euo pipefail
          LOG="${{ env.LOG_PATH }}"
          MODEL="${{ env.MODEL }}"

          RESULTS=$(grep -c '"event":"PROMPT_RESULT"' "$LOG" 2>/dev/null || echo 0)
          ERRORS=$(grep -c '"event":"PROMPT_ERROR"'  "$LOG" 2>/dev/null || echo 0)
          SUMMARIES=$(grep -c '"event":"STREAM_SUMMARY"' "$LOG" 2>/dev/null || echo 0)

          {
            echo "### ✅ UIA Bench (Claude) - Completed"
            echo
            echo "- **Model**: \`${MODEL}\`"
            echo "- **Log**: \`${LOG}\`"
            echo "- **Artifact**: uia-claude-results-${{ github.run_id }}"
            echo
            echo "- **Results**: ${RESULTS}"
            echo "- **Errors**: ${ERRORS}"
            echo "- **Stream Summaries**: ${SUMMARIES}"
          } >> "$GITHUB_STEP_SUMMARY"
